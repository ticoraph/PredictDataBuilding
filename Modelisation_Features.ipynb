{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Import des modules",
   "id": "f26b0e482324b34a"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-15T18:13:15.824763Z",
     "start_time": "2025-09-15T18:13:15.813283Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#Selection\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    GridSearchCV,\n",
    "    cross_validate,\n",
    ")\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "#Preprocess\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n",
    "\n",
    "#Modèles\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "bc = pd.read_csv('seatle_after_analyze.csv')"
   ],
   "outputs": [],
   "execution_count": 126
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Traitement des Types de Batiments\n",
    "- PrimaryPropertyType\n",
    "- Méthode pour numériser des catégories non ordonnées >>> LabelEncoder\n",
    "- Méthode pour numériser des catégories non ordonnées >>> one hot encoding"
   ],
   "id": "e243de12788bc826"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T18:13:15.837422Z",
     "start_time": "2025-09-15T18:13:15.830923Z"
    }
   },
   "cell_type": "code",
   "source": [
    "Column_To_Encode = 'PrimaryPropertyType'\n",
    "Label_Encode = 'LabelEncoder' + Column_To_Encode\n",
    "\n",
    "LabelEncoder = LabelEncoder()\n",
    "bc[Label_Encode] = LabelEncoder.fit_transform(bc[Column_To_Encode])\n",
    "#print(bc[[Column_To_Label_Encode, 'LabelEncoderColumn']].head())\n",
    "unique_pairs = bc[[Column_To_Encode, Label_Encode]].drop_duplicates().sort_values(Label_Encode)\n",
    "print(unique_pairs)"
   ],
   "id": "7facabd4a262c162",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              PrimaryPropertyType  LabelEncoderPrimaryPropertyType\n",
      "134           Distribution Center                                0\n",
      "1022                     Hospital                                1\n",
      "2                           Hotel                                2\n",
      "1                     K-12 School                                3\n",
      "356                    Laboratory                                4\n",
      "104                  Large Office                                5\n",
      "335          Low-Rise Multifamily                                6\n",
      "207                Medical Office                                7\n",
      "112            Mixed Use Property                                8\n",
      "1248                       Office                                9\n",
      "0                           Other                               10\n",
      "219        Refrigerated Warehouse                               11\n",
      "54                 Residence Hall                               12\n",
      "355                    Restaurant                               13\n",
      "24                   Retail Store                               14\n",
      "7           Self-Storage Facility                               15\n",
      "82          Senior Care Community                               16\n",
      "5     Small- and Mid-Sized Office                               17\n",
      "160   Supermarket / Grocery Store                               18\n",
      "46                     University                               19\n",
      "63                      Warehouse                               20\n",
      "86               Worship Facility                               21\n"
     ]
    }
   ],
   "execution_count": 127
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Traitement de la Localisation des Batiments\n",
    "- Neighborhood\n",
    "- Méthode pour numériser des catégories non ordonnées >>> one hot encoding"
   ],
   "id": "759a3868b18b7e1a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T18:13:15.846976Z",
     "start_time": "2025-09-15T18:13:15.841959Z"
    }
   },
   "cell_type": "code",
   "source": [
    "Column_To_Encode = 'Neighborhood'\n",
    "Label_Encode = 'LabelEncoder' + Column_To_Encode\n",
    "\n",
    "bc[Label_Encode] = LabelEncoder.fit_transform(bc[Column_To_Encode])\n",
    "#print(bc[[Column_To_Label_Encode, 'LabelEncoderColumn']].head())\n",
    "unique_pairs = bc[[Column_To_Encode, Label_Encode]].drop_duplicates().sort_values(Label_Encode)\n",
    "print(unique_pairs)"
   ],
   "id": "8eb3b0d7aed9d85e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Neighborhood  LabelEncoderNeighborhood\n",
      "9                 BALLARD                         0\n",
      "22                CENTRAL                         1\n",
      "62               DELRIDGE                         2\n",
      "0                DOWNTOWN                         3\n",
      "20                   EAST                         4\n",
      "10       GREATER DUWAMISH                         5\n",
      "5              LAKE UNION                         6\n",
      "8   MAGNOLIA / QUEEN ANNE                         7\n",
      "55                  NORTH                         8\n",
      "2               NORTHEAST                         9\n",
      "37              NORTHWEST                        10\n",
      "1               SOUTHEAST                        11\n",
      "68              SOUTHWEST                        12\n"
     ]
    }
   ],
   "execution_count": 128
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Traitement des Usages des Batiments",
   "id": "58659105a0aec6e8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T18:13:15.887521Z",
     "start_time": "2025-09-15T18:13:15.853905Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#ohe = OneHotEncoder(sparse_output=False)  # Newer versions\n",
    "#labels = ohe.fit_transform(bc[[\"ListOfAllPropertyUseTypes\"]])\n",
    "#bc_ohe = pd.DataFrame(labels, columns=ohe.get_feature_names_out([\"ListOfAllPropertyUseTypes\"]))\n",
    "#print(bc_ohe)\n",
    "\n",
    "# APPROCHE 1 : Transformer les données pour OneHotEncoder\n",
    "print(\"=\"*50)\n",
    "print(\"APPROCHE 1 : TRANSFORMATION DES DONNÉES\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "def prepare_data_for_onehot(df, column, delimiter=','):\n",
    "    \"\"\"\n",
    "    Prépare les données pour utiliser OneHotEncoder avec des valeurs multiples\n",
    "    \"\"\"\n",
    "    # Créer une liste de toutes les combinaisons\n",
    "    expanded_data = []\n",
    "    original_indices = []\n",
    "\n",
    "    for idx, values_str in df[column].items():\n",
    "        if pd.notna(values_str) and values_str.strip():\n",
    "            # Séparer les valeurs\n",
    "            values = [v.strip() for v in values_str.split(delimiter) if v.strip()]\n",
    "\n",
    "            # Créer une ligne pour chaque valeur\n",
    "            for value in values:\n",
    "                expanded_data.append(value)\n",
    "                original_indices.append(idx)\n",
    "\n",
    "    # Créer un DataFrame expandé\n",
    "    expanded_df = pd.DataFrame({\n",
    "        'original_index': original_indices,\n",
    "        'category': expanded_data\n",
    "    })\n",
    "\n",
    "    return expanded_df\n",
    "\n",
    "# Préparer les données\n",
    "expanded_df = prepare_data_for_onehot(bc, 'ListOfAllPropertyUseTypes')\n",
    "\n",
    "# --- Étape 1 : compter les occurrences\n",
    "counts = expanded_df.sum()\n",
    "\n",
    "# --- Étape 2 : définir les catégories fréquentes\n",
    "frequent_categories = counts[counts > 10].index\n",
    "\n",
    "# --- Étape 3 : remplacer les catégories rares par \"Autre\"\n",
    "expanded_df[\"ListOfAllPropertyUseTypes_clean\"] = expanded_df[\"category\"].apply(\n",
    "    lambda x: x if x in frequent_categories else \"Autre\"\n",
    ")\n",
    "\n",
    "# Utiliser OneHotEncoder sur les données expandues\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "encoded_expanded = encoder.fit_transform(expanded_df[['category']])\n",
    "\n",
    "# Obtenir les noms des features\n",
    "feature_names = encoder.get_feature_names_out(['category'])\n",
    "encoded_df_expanded = pd.DataFrame(encoded_expanded, columns=feature_names)\n",
    "encoded_df_expanded['original_index'] = expanded_df['original_index']\n",
    "\n",
    "# Regrouper par index original pour recombiner les valeurs multiples\n",
    "final_encoded = encoded_df_expanded.groupby('original_index')[feature_names].sum()\n",
    "# Convertir en binaire (0 ou 1) car sum peut donner des valeurs > 1\n",
    "final_encoded = (final_encoded > 0).astype(int)\n",
    "\n",
    "#print(\"Résultat final regroupé :\")\n",
    "print(final_encoded)\n",
    "#print()\n",
    "category_counts = final_encoded.sum(axis=0).sort_values(ascending=False)\n",
    "print(category_counts)\n",
    "\n",
    "\n"
   ],
   "id": "76e016dcf70e9975",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "APPROCHE 1 : TRANSFORMATION DES DONNÉES\n",
      "==================================================\n",
      "      original_index                               category\n",
      "0                  0  Other - Entertainment/Public Assembly\n",
      "1                  1                            K-12 School\n",
      "2                  2                                  Hotel\n",
      "3                  2                                Parking\n",
      "4                  3                  Automobile Dealership\n",
      "...              ...                                    ...\n",
      "2229            1256         Fitness Center/Health Club/Gym\n",
      "2230            1256                           Food Service\n",
      "2231            1256                                 Office\n",
      "2232            1256                     Other - Recreation\n",
      "2233            1256                     Pre-school/Daycare\n",
      "\n",
      "[2234 rows x 2 columns]\n",
      "original_index                                              1398094\n",
      "category          Other - Entertainment/Public AssemblyK-12 Scho...\n",
      "dtype: object\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'>' not supported between instances of 'str' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[129], line 47\u001B[0m\n\u001B[1;32m     44\u001B[0m \u001B[38;5;28mprint\u001B[39m(counts)\n\u001B[1;32m     46\u001B[0m \u001B[38;5;66;03m# --- Étape 2 : définir les catégories fréquentes\u001B[39;00m\n\u001B[0;32m---> 47\u001B[0m frequent_categories \u001B[38;5;241m=\u001B[39m counts[\u001B[43mcounts\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m>\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m10\u001B[39;49m]\u001B[38;5;241m.\u001B[39mindex\n\u001B[1;32m     49\u001B[0m \u001B[38;5;66;03m# --- Étape 3 : remplacer les catégories rares par \"Autre\"\u001B[39;00m\n\u001B[1;32m     50\u001B[0m expanded_df[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mListOfAllPropertyUseTypes_clean\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m expanded_df[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcategory\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mapply(\n\u001B[1;32m     51\u001B[0m     \u001B[38;5;28;01mlambda\u001B[39;00m x: x \u001B[38;5;28;01mif\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m frequent_categories \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAutre\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     52\u001B[0m )\n",
      "File \u001B[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/ops/common.py:76\u001B[0m, in \u001B[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001B[0;34m(self, other)\u001B[0m\n\u001B[1;32m     72\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mNotImplemented\u001B[39m\n\u001B[1;32m     74\u001B[0m other \u001B[38;5;241m=\u001B[39m item_from_zerodim(other)\n\u001B[0;32m---> 76\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmethod\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mother\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/arraylike.py:56\u001B[0m, in \u001B[0;36mOpsMixin.__gt__\u001B[0;34m(self, other)\u001B[0m\n\u001B[1;32m     54\u001B[0m \u001B[38;5;129m@unpack_zerodim_and_defer\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__gt__\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     55\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m__gt__\u001B[39m(\u001B[38;5;28mself\u001B[39m, other):\n\u001B[0;32m---> 56\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_cmp_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mother\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moperator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgt\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/series.py:6130\u001B[0m, in \u001B[0;36mSeries._cmp_method\u001B[0;34m(self, other, op)\u001B[0m\n\u001B[1;32m   6127\u001B[0m lvalues \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_values\n\u001B[1;32m   6128\u001B[0m rvalues \u001B[38;5;241m=\u001B[39m extract_array(other, extract_numpy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, extract_range\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m-> 6130\u001B[0m res_values \u001B[38;5;241m=\u001B[39m \u001B[43mops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcomparison_op\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   6132\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_construct_result(res_values, name\u001B[38;5;241m=\u001B[39mres_name)\n",
      "File \u001B[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/ops/array_ops.py:344\u001B[0m, in \u001B[0;36mcomparison_op\u001B[0;34m(left, right, op)\u001B[0m\n\u001B[1;32m    341\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m invalid_comparison(lvalues, rvalues, op)\n\u001B[1;32m    343\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m lvalues\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mobject\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(rvalues, \u001B[38;5;28mstr\u001B[39m):\n\u001B[0;32m--> 344\u001B[0m     res_values \u001B[38;5;241m=\u001B[39m \u001B[43mcomp_method_OBJECT_ARRAY\u001B[49m\u001B[43m(\u001B[49m\u001B[43mop\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrvalues\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    346\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    347\u001B[0m     res_values \u001B[38;5;241m=\u001B[39m _na_arithmetic_op(lvalues, rvalues, op, is_cmp\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/ops/array_ops.py:129\u001B[0m, in \u001B[0;36mcomp_method_OBJECT_ARRAY\u001B[0;34m(op, x, y)\u001B[0m\n\u001B[1;32m    127\u001B[0m     result \u001B[38;5;241m=\u001B[39m libops\u001B[38;5;241m.\u001B[39mvec_compare(x\u001B[38;5;241m.\u001B[39mravel(), y\u001B[38;5;241m.\u001B[39mravel(), op)\n\u001B[1;32m    128\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 129\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mlibops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscalar_compare\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mravel\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    130\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\u001B[38;5;241m.\u001B[39mreshape(x\u001B[38;5;241m.\u001B[39mshape)\n",
      "File \u001B[0;32mpandas/_libs/ops.pyx:107\u001B[0m, in \u001B[0;36mpandas._libs.ops.scalar_compare\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mTypeError\u001B[0m: '>' not supported between instances of 'str' and 'int'"
     ]
    }
   ],
   "execution_count": 129
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
